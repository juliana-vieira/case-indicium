# üíö Case Indicium - Programa Lighthouse

## üìã Sobre o Projeto

Este reposit√≥rio cont√©m o c√≥digo da minha solu√ß√£o para o desafio t√©cnico do **Programa Lighthouse** da empresa **Indicium**, focado em Engenharia de Dados. O projeto demonstra a implementa√ß√£o de um pipeline completo de dados: extra√ß√£o dos dados do banco relacional do cliente Banco Vit√≥ria, modelagem dimensional de um Data Warehouse e ingest√£o dos dados no mesmo.

### üéØ Objetivo
Desenvolver uma solu√ß√£o de dados focada em **extra√ß√£o e ingest√£o** que demonstre compet√™ncias t√©cnicas em:
- Engenharia de Dados
- Modelagem Dimensional
- Pipeline ETL
- Data Warehouse
- Orquestra√ß√£o de processos com Apache Airflow
  
---

## üèóÔ∏è Arquitetura do Projeto

### Diagrama de Fluxo de Dados

```mermaid
flowchart LR
    subgraph "Fontes de Dados"
        A1[CSV]
        A2[SQL]
    end

    subgraph "Apache Airflow"
        B1[Extra√ß√£o]
        B2[FileSystem Local<br/>Data Lake]
        B3[Carregamento]
        B4[PostgreSQL Local<br/>Data Warehouse]
        
        B1 --> B2
        B2 --> B3
        B3 --> B4
    end

    A1 --> B1
    A2 --> B1
```

---

## üóÑÔ∏è Modelagem do Data Warehouse

### Diagrama de Relacionamento

```mermaid
erDiagram
    DIM_AGENCIAS ||--o{ DIM_COLABORADOR_AGENCIA : "cod_agencia"
    DIM_COLABORADORES ||--o{ DIM_COLABORADOR_AGENCIA : "cod_colaborador"
    DIM_COLABORADORES ||--o{ FATO_PROPOSTAS : "cod_colaborador"
    DIM_CLIENTES ||--o{ FATO_PROPOSTAS : "cod_cliente"
    FATO_CONTAS ||--o{ FATO_TRANSACOES : "num_conta"
    DIM_CONTAS ||--o{ FATO_TRANSACOES : "num_conta"
    DIM_CONTAS ||--o{ FATO_CONTAS : "num_conta"

    DIM_AGENCIAS {
        int cod_agencia PK
        string nome
        string endereco
        string cidade
        string uf
        date data_abertura
        string tipo_agencia
        timestamp ultima_atualizacao
    }

    DIM_COLABORADOR_AGENCIA {
        int cod_colaborador PK
        int cod_agencia FK
        timestamp ultima_atualizacao
    }

    DIM_COLABORADORES {
        int cod_colaborador PK
        string primeiro_nome
        string ultimo_nome
        string email
        string cpf
        date data_nascimento
        string endereco
        string cep
        timestamp ultima_atualizacao
    }

    FATO_PROPOSTAS {
        int cod_proposta PK
        int cod_cliente FK
        int cod_colaborador FK
        date data_entrada_proposta
        decimal taxa_juros_mensal
        decimal valor_proposta
        decimal valor_financiamento
        decimal valor_entrada
        decimal valor_prestacao
        int quantidade_parcelas
        string carencia
        string status_proposta
        timestamp ultima_atualizacao
    }

    DIM_CLIENTES {
        int cod_cliente PK
        string primeiro_nome
        string ultimo_nome
        string email
        string tipo_cliente
        date data_inclusao
        string cpfcnpj
        date data_nascimento
        string endereco
        string cep
        timestamp ultima_atualizacao
    }

    FATO_TRANSACOES {
        int cod_transacao PK
        int num_conta FK
        date data_transacao
        string nome_transacao
        decimal valor_transacao
        timestamp ultima_atualizacao
    }

    FATO_CONTAS {
        int num_conta PK
        decimal saldo_total
        decimal saldo_disponivel
        date data_ultimo_lancamento
        timestamp ultima_atualizacao
    }

    DIM_CONTAS {
        int num_conta PK
        string tipo_conta
        date data_abertura
        int cod_cliente FK
        int cod_agencia FK
        int cod_colaborador FK
        timestamp ultima_atualizacao
    }
```

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Docker** - Containeriza√ß√£o da aplica√ß√£o e depend√™ncias
- **Apache Airflow** - Orquestra√ß√£o e agendamento de pipelines
- **PostgreSQL** - Banco de dados para Data Warehouse
- **Python** - Linguagem principal para ETL e processamento
- **SQL** - Manipula√ß√£o e consulta de dados
  
---

## üìä Pipeline de Dados

### Funcionalidades Implementadas:
- **Extra√ß√£o automatizada** de dados de m√∫ltiplas fontes
- **Armazenamento** de dados brutos em um Data Lake
- **Carregamento estruturado** no Data Warehouse PostgreSQL
- **Orquestra√ß√£o com Airflow** para agendamento e monitoramento
- **Modelagem dimensional** para an√°lises otimizadas

---

## ‚ö†Ô∏è Limita√ß√µes Conhecidas

Este projeto foi desenvolvido para fins de **demonstra√ß√£o t√©cnica** e possui as seguintes limita√ß√µes:

### üî¥ Data Lake Simulado
- Utiliza sistema de arquivos local para simular um Data Lake em vez de uma solu√ß√£o cloud (AWS S3, Azure Data Lake, etc.)

### üî¥ Aus√™ncia de CDC (Change Data Capture)
- Os dados mais atualizados s√£o determinados de acordo com a data do diret√≥rio do Data Lake
- N√£o captura mudan√ßas em tempo real 
- Dados podem ficar desatualizados entre execu√ß√µes

### üî¥ Ambiente de Desenvolvimento
- Configura√ß√£o simplificada para demonstra√ß√£o
- Execu√ß√£o em containers locais via Docker
- Sem pipeline CI/CD implementado
- Logs e monitoramento b√°sicos

---

## üéØ Melhorias Futuras

Para uma implementa√ß√£o em produ√ß√£o, seria necess√°rio:

1. **Implementar CDC** para captura de mudan√ßas em tempo real
2. **Migrar para Data Lake real** (AWS S3, Azure Data Lake, GCP Cloud Storage)
3. **Adicionar orquestra√ß√£o avan√ßada** com recursos enterprise do Airflow
4. **Implementar data quality** e valida√ß√µes autom√°ticas robustas
5. **Adicionar monitoramento** e alertas avan√ßados
6. **Configurar pipeline CI/CD** para automa√ß√£o de deploys
7. **Implementar data lineage** e cataloga√ß√£o de dados
8. **Adicionar testes automatizados** para os pipelines
9. **Configurar backup e recovery** dos dados
10. **Implementar seguran√ßa** e controle de acesso

---

## üë• Contato

**Juliana Vieira**
- LinkedIn: [linkedin.com/in/juliana-vieira](https://linkedin.com/in/juliana-vieira)
- Email: julianasalustianovieira@gmail.com

---

*Projeto desenvolvido com üíö para o Programa Lighthouse 2025*
